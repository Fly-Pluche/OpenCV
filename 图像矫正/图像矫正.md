# 相关依赖

- OpenCV
- Numpy
- argparse
- matplotlib 

# Canny边缘检测

Canny 边缘检测是一种使用多级边缘检测算法检测边缘的方法。1986 年，John F. Canny 发
表了著名的论文 A Computational Approach to Edge Detection，在该论文中详述了如何进行边缘
检测。

边缘检测分为四步骤：
步骤 1：去噪。
步骤 2：计算梯度的幅度与方向。
步骤 3：非极大值抑制，即适当地让边缘“变瘦”。
步骤 4：确定边缘。使用双阈值算法确定最终的边缘信息。

### 去噪
采用高斯滤波去除图像噪声。
		由于图像边缘非常容易受到噪声的干扰，因此为了避免检测到错误的边缘信息，通常需要对图像进行滤波以去除噪声。滤波的目的是平滑一些纹理较弱的非边缘区域，以便得到更准确的边缘。在实际处理过程中，通常采用高斯滤波去除图像中的噪声。

在滤波过程中，我们通过滤波器对像素点周围的像素计算加权平均值，获取最终滤波结果。滤波器的大小也是可变的，高斯核的大小对于边缘检测的效果具有很重要的作用。滤波器
的核越大，边缘信息对于噪声的敏感度就越低。不过，核越大，边缘检测的定位错误也会随之增加。通常来说，一个 5×5 的核能够满足大多数的情况。

### 计算梯度

*梯度*的本意是一个向量（矢量），表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此*梯度*的方向）变化最快，变化率最大（为该*梯度*的模）。

而图像中的梯度就是图像变化最剧烈的地方，例如边缘。边缘处图像变化最为剧烈。梯度的方向与边缘的方向是垂直的。

边缘检测算子返回水平方向的Gx和垂直方向的Gy。梯度的幅度𝐺和方向𝛩（用角度值表示）为：

<img src="https://gitee.com/Black_Friday/blog/raw/master/image/202202222038932.png" alt="image-20220222203814684" style="zoom:50%;" />

式中，atan2(•)表示具有两个参数的 arctan 函数。

梯度的方向总是与边缘垂直的，通常就近取值为水平（左、右）、垂直（上、下）、对角线（右上、左上、左下、右下）等 8 个不同的方向。

因此，在计算梯度时，我们会得到梯度的幅度和角度（代表梯度的方向）两个值。
图 （） 展示了梯度的表示法。其中，每一个梯度包含幅度和角度两个不同的值。为了方便观察，这里使用了可视化表示方法。例如，左上角顶点的值“2 ↑”实际上表示的是一个二元数对“(2, 90)”，表示梯度的幅度为 2，角度为 90°。

![image-20220222204223754](https://gitee.com/Black_Friday/blog/raw/master/image/202202222042840.png)



## 非极大值抑制

非极大值抑制（NMS）Non-Maximum Suppression。广泛的应用于计算机视觉任务中如：边缘检测、目标检测等，在不同应用中的具体实现不太一样，但思想是一样的：搜素局部最大值，抑制极大值。

获得了梯度的幅度和方向后，遍历图像中的像素点，去除所有非边缘的点。在具体实现时，逐一遍历像素点，判断当前像素点是否是周围像素点中具有相同梯度方向的最大值，并根据判断结果决定是否抑制该点。通过以上描述可知，该步骤是边缘细化的过程。

针对每一个像素点：

- 如果该点是正/负梯度方向上的局部最大值，则保留。
- 否则，抑制该点（归零）。



### 双阈值确定边缘

完成上述步骤后，图像内的强边缘已经在当前获取的边缘图像内。但是，一些虚边缘可能也在边缘图像内。这些虚边缘可能是真实图像产生的，也可能是由于噪声所产生的。

为了剔除噪声产生的边缘，设置两个阈值，其中一个为高阈值 maxVal，另一个为低阈值 minVal。根据当前边缘像素的梯度值（指的是梯度幅度，下同）与这两个阈值之间的关系，判断边缘的属性。具体步骤为：

- 如果当前边缘像素的梯度值大于或等于 maxVal，则将当前边缘像素标记为强边缘。
- 如果当前边缘像素的梯度值介于 maxVal 与 minVal 之间，则将当前边缘像素标记为虚
  边缘（需要保留）。
- 如果当前边缘像素的梯度值小于或等于 minVal，则抑制当前边缘像素。

在上述过程中，对于得到的虚边缘，需要对其做进一步处理。一般通过判断虚边缘与强边缘是否连接，来确定虚边缘到底属于哪种情况。通常情况下，如果一个虚边缘：

- 与强边缘连接，则将该边缘处理为强边缘。
- 与强边缘无连接，则该边缘为弱边缘，将其抑制。

强边缘就是最后检测出的真正边缘。





## cv2.HoughLinesP 霍夫变换

1. 霍夫线变换常用于提取直线，圆等几何形状.
2. 是用霍夫线变换之前, 首先要对图像进行边缘检测的处理，也即霍夫线变换的直接输入只能是边缘二值图像.

![image-20220222215947735](https://gitee.com/Black_Friday/blog/raw/master/image/202202222159000.png)



下面要提到笛卡尔坐标系（直角坐标系），霍夫空间，极坐标系。

首先霍夫空间的直线映射到笛卡尔坐标系中是一个点（反之相同）。

![image-20220222221527855](https://gitee.com/Black_Friday/blog/raw/master/image/202202222215101.png)

所以对于原空间的两个点，将其映射到另一个空间后的得到两条直线的交点，交点逆映射回去便是过原空间两点的直线。

![image-20220222221545664](https://gitee.com/Black_Friday/blog/raw/master/image/202202222215809.png)

对于多点线的情况，需要只需选取交点较多的情况：

![image-20220222221929169](https://gitee.com/Black_Friday/blog/raw/master/image/202202222219318.png)



![image-20220222222030767](https://gitee.com/Black_Friday/blog/raw/master/image/202202222220881.png)



但是对于直线是x=2这种情况，便无法解决（k，q）

<img src="https://gitee.com/Black_Friday/blog/raw/master/image/202202222220275.png" alt="image-20220222222056200" style="zoom:50%;" />

为了解决这种情况，将用 *极坐标系* 来表示直线. 因此, 直线的表达式可为:

![y = \left ( -\dfrac{\cos \theta}{\sin \theta} \right ) x + \left ( \dfrac{r}{\sin \theta} \right )](http://www.opencv.org.cn/opencvdoc/2.3.2/html/_images/math/3050cf05bd6f4d9b2623357fb1cc399905d75943.png)

<img src="https://gitee.com/Black_Friday/blog/raw/master/image/202202222223499.png" alt="image-20220222222345410" style="zoom:50%;" />

化简得: ![r = x \cos \theta + y \sin \theta](https://gitee.com/Black_Friday/blog/raw/master/image/202202222224866.png)



对于一个给定点 $(x_0,y_0)$ 我们在极坐标对极径极角平面绘出所有通过它的直线, 将得到一条正弦曲线. 例如, 对于给定点 $x_0=8$and $y_0=6$我们可以绘出下图 :

<img src="https://gitee.com/Black_Friday/blog/raw/master/image/202202222226094.png" alt="image-20220222222633018" style="zoom:50%;" />

多条曲线求交点：

<img src="https://gitee.com/Black_Friday/blog/raw/master/image/202202222226227.png" alt="image-20220222222651148" style="zoom:50%;" />



一条直线能够通过在平面寻找交于一点的曲线数量来 *检测*. 越多曲线交于一点也就意味着这个交点表示的直线由更多的点组成. 一般来说我们可以通过设置直线上点的 *阈值* 来定义多少条曲线交于一点我们才认为 *检测* 到了一条直线.

这就是霍夫线变换要做的. 它追踪图像中每个点对应曲线间的交点. 如果交于一点的曲线的数量超过了 *阈值*, 那么可以认为这个交点所代表的参数对在原图像中为一条直线.



1. **标准霍夫线变换**

> - 原理在上面的部分已经说明了. 它能给我们提供一组参数对 ![(\theta, r_{\theta})](http://www.opencv.org.cn/opencvdoc/2.3.2/html/_images/math/7e065ce45efb160a92773b6c4aad65a309d7535e.png) 的集合来表示检测到的直线
> - 在OpenCV 中通过函数 HoughLines来实现

2. **统计概率霍夫线变换**

> - 执行起来效率更高的霍夫线变换. 它输出检测到的直线的端点 ![(x_{0}, y_{0}, x_{1}, y_{1})](https://gitee.com/Black_Friday/blog/raw/master/image/202202222148435.png)
> - 在OpenCV 中它通过函数 HoughLinesP来实现

我们在代码中采用统计概率霍夫线变换进行。

cv2.HoughLinesP的参数：

1、image – 8-bit, single-channel binary source image. The image may be modified by the function. 输入的图像应该是8位单通道二值图像 

2、lines – Output vector of lines. Each line is represented by a 4-element vector (x_1, y_1, x_2, y_2) , where(x_1,y_1) and (x_2, y_2) are the ending points of each detected line segment. rho – Distance resolution of the accumulator in pixels. 输出的矢量。输出的两点是线段的两个端点 

3、rho – Distance resolution of the accumulator in pixels. 极径参数的距离分辨率 

4、theta – Angle resolution of the accumulator in radians. 极角参数的角度分辨率 

5、threshold – Accumulator threshold parameter. Only those lines are returned that get enough votes (>\texttt{threshold} ). 设定的阈值，大于此阈值的交点，才会被认为是一条直线 

6、minLineLength – Minimum line length. Line segments shorter than that are rejected. 
线段的最小长度 

7、maxLineGap – Maximum allowed gap between points on the same line to link them. 点到直线被允许的最大距离 





# 透视变换



变换有两种：

透视变换与仿射变换 

在应用层面，仿射变换是图像基于3个固定顶点的变换，如图所示：

![img](https://pic1.zhimg.com/80/v2-362633287ba80cd94a9f4efaf1ab31d8_720w.png)

图中红点即为固定顶点，在变换先后固定顶点的像素值不变，图像整体则根据变换规则进行变换

同理，透视变换是图像基于4个固定顶点的变换，如图所示：

![img](https://gitee.com/Black_Friday/blog/raw/master/image/202202222312420.png)



透视变换是将图像从一个视平面投影到另外一个视平面的过程，所以透视变换也被称为投影映射（Projection Mapping）。

我们知道在图像的仿射变换中需要变换矩阵是一个2x3的两维平面变换矩阵，而透视变换本质上空间立体三维变换，根据其次坐标方差，要把三维坐标投影到另外一个视平面，就需要一个完全不同的变换矩阵M，所以这个是透视变换跟OpenCV中几何仿射变换最大的不同。 
OpenCV中透视变换的又分为两种：

- 稀疏透视变换

- 密集透视变换

我们经常提到的对图像的透视变换都是指密集透视变换，而稀疏透视变换在OpenCV的特征点匹配之后的特征对象区域标识中经常用到。一般情况下密集透视变换warpPerspective函数常与函数getPerspectiveTransform一起使用实现对图像的透视校正。而稀疏透视变换perspectiveTransform经常与findhomography一起使用。







## 原理公式

感觉原理还是比较好理解的，涉及到线性代数的空间变换。

![image-20220222231505399](https://gitee.com/Black_Friday/blog/raw/master/image/202202222315491.png)

u,v是原始图片左边，对应得到变换后的图片坐标x,y,其中![img](https://gitee.com/Black_Friday/blog/raw/master/image/202202222315076.png)。

变换矩阵![img](https://img-blog.csdn.net/20180422095850237?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5nanVucDM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)可以分作四部分来理解，![img](https://img-blog.csdn.net/20180422095915794?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5nanVucDM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)表示线性变换，![img](https://gitee.com/Black_Friday/blog/raw/master/image/202202222315722.png)表示平移，![img](https://img-blog.csdn.net/20180422100021279?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5nanVucDM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)产生透视。

平移好理解，就是偏置，至于透视，以及上式中的w，我认为可以看做第三维坐标z，就是把一个三维空间降维为二维空间。求解出的变换矩阵就可以将一个正方形变换到四边形。

![img](https://gitee.com/Black_Friday/blog/raw/master/image/202202222319241.png)



```python
import argparse
import numpy as np
import cv2
from matplotlib import pyplot as plt

min_weight = 150


# 线段类
class Line:
    def __init__(self, line):
        # x1, y1, x2, y2 = l # 前两个数为起点，后两个数为终点
        self.x1 = line[0]
        self.y1 = line[1]
        self.x2 = line[2]
        self.y2 = line[3]
        # 线段中点的坐标, 为排序使用
        self.half_x = (self.x1 + self.x2) / 2
        self.half_y = (self.y1 + self.y2) / 2

    # 求出与另外一条不平行线段延长线的交点
    def get_cross_point(self, l_a):
        a1 = self.y2 - self.y1
        b1 = self.x1 - self.x2
        c1 = a1 * self.x1 + b1 * self.y1
        a2 = l_a.y2 - l_a.y1
        b2 = l_a.x1 - l_a.x2
        c2 = a2 * l_a.x1 + b2 * l_a.x2
        d = a1 * b2 - a2 * b1
        if d == 0:  # 平行或共线的情况
            raise ValueError
        return (1. * (b2 * c1 - b1 * c2) / d, 1. * (a1 * c2 - a2 * c1) / d)


# 对图像进行预处理求出图像中的直线
def img_process(old_img):
    # 重新设定图像大小，方便计算
    height = old_img.shape[0]
    weight = old_img.shape[1]
    scale = min(10., weight * 1. / min_weight)
    new_h = int(height * 1. / scale)
    new_w = int(weight * 1. / scale)
    new_img = cv2.resize(old_img, (new_w, new_h))
    # old_img = cv2.GaussianBlur(old_img, (15, 15),sigmaX=0,sigmaY=0)
    old_img = cv2.resize(old_img, (new_w, new_h))
    gray_img = cv2.cvtColor(old_img, cv2.COLOR_BGR2GRAY)  # 转为灰度图像
    # 利用Canny 边缘检测和霍夫变换提取直线
    #  二值化
    highthreshold = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[0]
    lowthreshold = highthreshold * 0.2
    canny_img = cv2.Canny(gray_img, lowthreshold, highthreshold)
    cv2.imshow('a', canny_img)
    cv2.waitKey(0)
    return cv2.HoughLinesP(canny_img, 1, np.pi / 180, new_w // 3, 50, new_w // 3, 20), new_img


# 获得四个目标点
def get_target_points(lines, img):
    # 分别提取出水平和垂直的线段

    lines_h = []  # 存放接近水平的线段
    lines_v = []  # 存放接近垂直的线段
    lines1 = lines[:, 0, :]  # 提取为二维
    for l in lines1:
        line = Line(l)
        if abs(line.x1 - line.x2) > abs(line.y1 - line.y2):
            lines_h.append(line)
        else:
            lines_v.append(line)

    # 如果线段数不够两条, 直接用原图像的边缘替代
    if len(lines_h) <= 1:
        if not lines_h or lines_h[0].half_y > img.shape[0] / 2:
            lines_h.append(Line((0, 0, img.shape[1] - 1, 0)))
        if not lines_h or lines_h[0].half_y <= img.shape[0] / 2:
            lines_h.append(Line((0, img.shape[0] - 1, img.shape[1] - 1, img.shape[0] - 1)))
    if len(lines_v) <= 1:
        if not lines_v or lines_v[0].half_x > img.shape[1] / 2:
            lines_v.append(Line((0, 0, 0, img.shape[0] - 1)))
        if not lines_v or lines_v[0].half_x <= img.shape[1] / 2:
            lines_v.append(Line((img.shape[1] - 1, 0, img.shape[1] - 1, img.shape[0] - 1)))

    # 获取最靠近边缘的四条线段求出他们的交点
    lines_h.sort(key=lambda line: line.half_y)
    lines_v.sort(key=lambda line: line.half_x)
    return [lines_h[0].get_cross_point(lines_v[0]),
            lines_h[0].get_cross_point(lines_v[-1]),
            lines_h[-1].get_cross_point(lines_v[0]),
            lines_h[-1].get_cross_point(lines_v[-1])]


# 做透视变换
def per_transform(target_points, old_img):
    height = old_img.shape[0]
    weight = old_img.shape[1]
    scale = min(10., weight * 1. / min_weight)
    # 恢复为原图像大小
    for i, p in enumerate(target_points):
        x, y = p
        target_points[i] = (x * scale, y * scale)
    # target_points = [(109, 58), (651, 132), (111, 361), (688, 325)]
    # target_points = [(339, 340), (1170, 258), (128, height-288), (weight-116, height-297)]
    # 原图像的四个点
    four_points = np.array(((0, 0),
                            (weight - 1, 0),
                            (0, height - 1),
                            (weight - 1, height - 1)),
                           np.float32)
    target_points = np.array(target_points, np.float32)
    M = cv2.getPerspectiveTransform(target_points, four_points)
    return cv2.warpPerspective(old_img, M, (weight, height))


if __name__ == '__main__':
    parser = argparse.ArgumentParser(prog='test.py')
    parser.add_argument('--path', type=str, default='D:/0.jpg ')
    parser.add_argument('--save', type=str, default='D:/03.jpg ')
    opt = parser.parse_args()

    old_img = cv2.imread(opt.path)
    lines, new_img = img_process(old_img)
    t_points = get_target_points(lines, new_img)
    revert_img = per_transform(t_points, old_img)
    cv2.imwrite(opt.save, revert_img)
    plt.imshow(revert_img, )
    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis
    plt.show()
```